{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of emerging technologies using NLP-powered patent networks\n",
    "\n",
    "## Robustness checks\n",
    "\n",
    "> Author: **Antoine MATHIEU COLLIN**\n",
    "* Department of Management, Strategy and Innovation (MSI) of the Faculty of Economics and Business (FEB), KU Leuven\n",
    "* Department of Computer Science of the Faculty of Engineering Science, KU Leuven\n",
    "* Leuven.AI, KU Leuven Institute for Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 1. Loading the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# location of the PATSTAT data previously retrieved with the data_extraction_from_PATSTAT.ipynb notebook\n",
    "output_files_prefix = \"wind_tech_1990_2020_with_publications\"\n",
    "pre = '../data/raw/' + output_files_prefix\n",
    "suf = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# for convenience, we store all the data retrieved into a single data object.\n",
    "data = {'_table_main_patent_infos': pd.read_csv(pre + '_table_main_patent_infos' + suf, low_memory=False),\n",
    "       '_table_cpc': pd.read_csv(pre + '_table_cpc' + suf, low_memory=False), \n",
    "       '_table_patentees_info': pd.read_csv(pre + '_table_patentees_info' + suf, low_memory=False),\n",
    "       '_table_backward_docdb_citations': pd.read_csv(pre + '_table_backward_docdb_citations' + suf, low_memory=False),\n",
    "       '_table_forward_docdb_citations': pd.read_csv(pre + '_table_forward_docdb_citations' + suf, low_memory=False),\n",
    "       '_text_data':pd.read_csv('../data/raw/wind_tech_1990_2020_with_publications_full_text.csv', sep = ',')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>appln_id</th>\n",
       "      <th>appln_id.1</th>\n",
       "      <th>appln_auth</th>\n",
       "      <th>appln_nr</th>\n",
       "      <th>appln_kind</th>\n",
       "      <th>appln_filing_date</th>\n",
       "      <th>appln_filing_year</th>\n",
       "      <th>appln_nr_epodoc</th>\n",
       "      <th>appln_nr_original</th>\n",
       "      <th>...</th>\n",
       "      <th>pat_publn_id</th>\n",
       "      <th>publn_auth</th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>publn_nr_original</th>\n",
       "      <th>publn_kind</th>\n",
       "      <th>appln_id.6</th>\n",
       "      <th>publn_date</th>\n",
       "      <th>publn_lg</th>\n",
       "      <th>publn_first_grant</th>\n",
       "      <th>publn_claims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>EP</td>\n",
       "      <td>07015148</td>\n",
       "      <td>A</td>\n",
       "      <td>2007-08-02</td>\n",
       "      <td>2007</td>\n",
       "      <td>EP20070015148</td>\n",
       "      <td>07015148</td>\n",
       "      <td>...</td>\n",
       "      <td>278556884</td>\n",
       "      <td>EP</td>\n",
       "      <td>1892412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1</td>\n",
       "      <td>146</td>\n",
       "      <td>2008-02-27</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>EP</td>\n",
       "      <td>07015148</td>\n",
       "      <td>A</td>\n",
       "      <td>2007-08-02</td>\n",
       "      <td>2007</td>\n",
       "      <td>EP20070015148</td>\n",
       "      <td>07015148</td>\n",
       "      <td>...</td>\n",
       "      <td>278556884</td>\n",
       "      <td>EP</td>\n",
       "      <td>1892412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1</td>\n",
       "      <td>146</td>\n",
       "      <td>2008-02-27</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>EP</td>\n",
       "      <td>07015148</td>\n",
       "      <td>A</td>\n",
       "      <td>2007-08-02</td>\n",
       "      <td>2007</td>\n",
       "      <td>EP20070015148</td>\n",
       "      <td>07015148</td>\n",
       "      <td>...</td>\n",
       "      <td>278556884</td>\n",
       "      <td>EP</td>\n",
       "      <td>1892412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1</td>\n",
       "      <td>146</td>\n",
       "      <td>2008-02-27</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>EP</td>\n",
       "      <td>07015148</td>\n",
       "      <td>A</td>\n",
       "      <td>2007-08-02</td>\n",
       "      <td>2007</td>\n",
       "      <td>EP20070015148</td>\n",
       "      <td>07015148</td>\n",
       "      <td>...</td>\n",
       "      <td>335943971</td>\n",
       "      <td>EP</td>\n",
       "      <td>1892412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B1</td>\n",
       "      <td>146</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>de</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>EP</td>\n",
       "      <td>07015148</td>\n",
       "      <td>A</td>\n",
       "      <td>2007-08-02</td>\n",
       "      <td>2007</td>\n",
       "      <td>EP20070015148</td>\n",
       "      <td>07015148</td>\n",
       "      <td>...</td>\n",
       "      <td>335943971</td>\n",
       "      <td>EP</td>\n",
       "      <td>1892412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B1</td>\n",
       "      <td>146</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>de</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  appln_id  appln_id.1 appln_auth  appln_nr appln_kind  \\\n",
       "0      0       146         146         EP  07015148         A    \n",
       "1      0       146         146         EP  07015148         A    \n",
       "2      0       146         146         EP  07015148         A    \n",
       "3      0       146         146         EP  07015148         A    \n",
       "4      0       146         146         EP  07015148         A    \n",
       "\n",
       "  appln_filing_date  appln_filing_year appln_nr_epodoc appln_nr_original  ...  \\\n",
       "0        2007-08-02               2007   EP20070015148          07015148  ...   \n",
       "1        2007-08-02               2007   EP20070015148          07015148  ...   \n",
       "2        2007-08-02               2007   EP20070015148          07015148  ...   \n",
       "3        2007-08-02               2007   EP20070015148          07015148  ...   \n",
       "4        2007-08-02               2007   EP20070015148          07015148  ...   \n",
       "\n",
       "  pat_publn_id publn_auth  publn_nr publn_nr_original publn_kind appln_id.6  \\\n",
       "0    278556884         EP   1892412               NaN         A1        146   \n",
       "1    278556884         EP   1892412               NaN         A1        146   \n",
       "2    278556884         EP   1892412               NaN         A1        146   \n",
       "3    335943971         EP   1892412               NaN         B1        146   \n",
       "4    335943971         EP   1892412               NaN         B1        146   \n",
       "\n",
       "   publn_date  publn_lg  publn_first_grant publn_claims  \n",
       "0  2008-02-27        de                  0            7  \n",
       "1  2008-02-27        de                  0            7  \n",
       "2  2008-02-27        de                  0            7  \n",
       "3  2011-07-27        de                  1            6  \n",
       "4  2011-07-27        de                  1            6  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['_table_main_patent_infos'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run model_API.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Robutness checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data cleaning statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiation of the model\n",
    "model = Model()\n",
    "# fitting the model to the data\n",
    "model._input_data(data)\n",
    "# new metrics\n",
    "model._compute_new_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     10,
     99,
     115,
     133,
     141,
     146,
     159,
     165,
     180,
     193
    ]
   },
   "outputs": [],
   "source": [
    "class wrap:\n",
    "    \"\"\"\n",
    "    Creates a table with, for each data cleaning step:\n",
    "    - Nb of patents\n",
    "    - Nb of patent families\n",
    "    - Average count of famility citations\n",
    "    - Proportion of patents for which the claim text data is available\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def select_columns(data):\n",
    "        \"\"\"We remove the columns called 'index' as they are unuseful and perturb the merge\"\"\"\n",
    "\n",
    "        cols = ['appln_id',\n",
    "                'appln_auth',\n",
    "                'appln_nr',\n",
    "                'appln_kind',\n",
    "                'appln_filing_date',\n",
    "                'appln_filing_year',\n",
    "                'appln_nr_epodoc',\n",
    "                'appln_nr_original',\n",
    "                'ipr_type',\n",
    "                'receiving_office',\n",
    "                'internat_appln_id',\n",
    "                'int_phase',\n",
    "                'reg_phase',\n",
    "                'nat_phase',\n",
    "                'earliest_filing_date',\n",
    "                'earliest_filing_year',\n",
    "                'earliest_filing_id',\n",
    "                'earliest_publn_date',\n",
    "                'earliest_publn_year',\n",
    "                'earliest_pat_publn_id',\n",
    "                'granted',\n",
    "                'docdb_family_id',\n",
    "                'inpadoc_family_id',\n",
    "                'docdb_family_size',\n",
    "                'nb_citing_docdb_fam',\n",
    "                'nb_applicants',\n",
    "                'nb_inventors',\n",
    "                'appln_title_lg',\n",
    "                'appln_title',\n",
    "                'appln_abstract_lg',\n",
    "                'appln_abstract',\n",
    "                'ipc_class_symbol',\n",
    "                'ipc_class_level',\n",
    "                'ipc_version',\n",
    "                'ipc_value',\n",
    "                'ipc_position',\n",
    "                'ipc_gener_auth',\n",
    "                'nace2_code',\n",
    "                'weight',\n",
    "                'pat_publn_id',\n",
    "                'publn_auth',\n",
    "                'publn_nr',\n",
    "                'publn_nr_original',\n",
    "                'publn_kind',\n",
    "                'publn_date',\n",
    "                'publn_lg',\n",
    "                'publn_first_grant',\n",
    "                'publn_claims']\n",
    "\n",
    "        data['_table_main_patent_infos'] = data['_table_main_patent_infos'][cols]\n",
    "\n",
    "        cols = ['appln_id',\n",
    "                'person_id',\n",
    "                'applt_seq_nr',\n",
    "                'invt_seq_nr',\n",
    "                'person_name',\n",
    "                'person_address',\n",
    "                'person_ctry_code',\n",
    "                'doc_std_name_id',\n",
    "                'doc_std_name',\n",
    "                'psn_id',\n",
    "                'psn_name',\n",
    "                'psn_level',\n",
    "                'psn_sector',\n",
    "                'person_orig_id',\n",
    "                'source',\n",
    "                'source_version',\n",
    "                'name_freeform',\n",
    "                'last_name',\n",
    "                'first_name',\n",
    "                'middle_name',\n",
    "                'address_freeform',\n",
    "                'address_1',\n",
    "                'address_2',\n",
    "                'address_3',\n",
    "                'address_4',\n",
    "                'address_5',\n",
    "                'street',\n",
    "                'city',\n",
    "                'zip_code',\n",
    "                'state',\n",
    "                'residence_ctry_code',\n",
    "                'role']\n",
    "        data['_table_patentees_info'] = data['_table_patentees_info'][cols]\n",
    "        return data\n",
    "\n",
    "    def reshape_PATSTAT_data(data):\n",
    "        \"\"\" Reshaping PATSTAT data \"\"\"\n",
    "\n",
    "        # retrieve variables of interest from the PATSTAT dataset\n",
    "        cols = ['appln_id','appln_filing_year','appln_auth','publn_auth',\n",
    "                'publn_nr','publn_nr_original','publn_lg']\n",
    "\n",
    "        table_PATSTAT = data['_table_main_patent_infos']\n",
    "        cols = [col for col in list(table_PATSTAT) if col != 'publn_nr' and col != 'publn_nr_original']\n",
    "\n",
    "        table_PATSTAT = pd.melt(table_PATSTAT,\n",
    "                                id_vars=cols,\n",
    "                                var_name='type_publication_nb',\n",
    "                                value_name='publn_nr')\n",
    "        return table_PATSTAT\n",
    "    \n",
    "    def reshape_EP_full_text_data(data):\n",
    "        \"\"\" Reshapes the EP full text data to be able to assess the wether a PATSTAT patent is present\n",
    "        in the database \"\"\"\n",
    "\n",
    "        # retrieve variables of interest from the EP full text data\n",
    "        table_EP_full_text = data['_text_data']\n",
    "        # renaming the publication number column to align with PATSTAT before merging\n",
    "        table_EP_full_text.rename(columns={'publication_number':  'publn_nr'}, inplace = True)\n",
    "        # keep only patent which contains claims\n",
    "        condition = table_EP_full_text['text_type'] == 'CLAIM'\n",
    "        table_EP_full_text = table_EP_full_text[condition]\n",
    "        # drop duplicates and keep only 2 variables\n",
    "        table_EP_full_text = table_EP_full_text[['publn_nr', 'text_type']]\n",
    "        table_EP_full_text.drop_duplicates(inplace = True)\n",
    "        # store the ids as str\n",
    "        table_EP_full_text['publn_nr'] = table_EP_full_text['publn_nr'].astype(str)\n",
    "        return table_EP_full_text\n",
    "    \n",
    "    def add_citations(data, table_PATSTAT):\n",
    "        \"\"\"Adds the citation count to the data\"\"\"\n",
    "\n",
    "        df = data['_table_main_patent_infos']\n",
    "        mapp = dict(zip(df['appln_id'],df['nb_citing_docdb_fam']))\n",
    "        table_PATSTAT['nb_citing_docdb_fam'] = table_PATSTAT['appln_id'].map(mapp)\n",
    "        return table_PATSTAT\n",
    "    \n",
    "    def merge_data(data):\n",
    "        return pd.merge(left = data['_table_main_patent_infos'],\n",
    "                        right = data['_table_patentees_info'],\n",
    "                        on='appln_id')\n",
    "    \n",
    "    def merge_final_datasets(table_EP_full_text, table_PATSTAT):\n",
    "    \n",
    "        # merging the two datasets \n",
    "        mapp = dict(zip(table_EP_full_text['publn_nr'],table_EP_full_text['text_type']))\n",
    "        table_PATSTAT['claims_availability'] = table_PATSTAT['publn_nr'].map(mapp).fillna('No')\n",
    "        mapp = {}\n",
    "        mapp['CLAIM'] = 'Yes'\n",
    "        table_PATSTAT['claims_availability'] = table_PATSTAT['claims_availability'].map(mapp).fillna(table_PATSTAT['claims_availability'])\n",
    "        # if we have a claim, we drop duplicates for the other (unmatched) publication numbers\n",
    "        table_PATSTAT.sort_values(by = 'claims_availability', ascending = False, inplace = True)\n",
    "        table_PATSTAT.drop_duplicates(subset = 'appln_id', inplace = True)\n",
    "        return table_PATSTAT\n",
    "    \n",
    "    def set_plotting_style():\n",
    "        import matplotlib.pyplot as plt\n",
    "        # use the 'seaborn-colorblind' style\n",
    "        plt.style.use('seaborn-paper')\n",
    "        sns.set(rc={'figure.figsize':(16,4)})\n",
    "        \n",
    "    def plot_claim_data_availability(table_PATSTAT):\n",
    "\n",
    "        import seaborn as sns\n",
    "        df = table_PATSTAT[table_PATSTAT['appln_auth']=='EP']\n",
    "\n",
    "        # data availability according to patent authority\n",
    "        #g = sns.countplot(x='granted', hue='claims_availability', data=table_PATSTAT)\n",
    "        #g.set_xticklabels(g.get_xticklabels(), rotation=90);\n",
    "        \n",
    "        ## I WAS THERE\n",
    "        nb_claims_available = len(table_PATSTAT[table_PATSTAT['claims_availability']=='Yes'])\n",
    "        proportion_of_claims_available = nb_claims_available/len(table_PATSTAT)*100\n",
    "        \n",
    "        return proportion_of_claims_available\n",
    "        \n",
    "    def display_claims_availability(data):\n",
    "        data = wrap.select_columns(data)\n",
    "        df = wrap.merge_data(data)\n",
    "\n",
    "        table_PATSTAT = wrap.reshape_PATSTAT_data(data)\n",
    "        table_PATSTAT = wrap.add_citations(data, table_PATSTAT)\n",
    "        table_EP_full_text = wrap.reshape_EP_full_text_data(data)\n",
    "        table_PATSTAT = wrap.merge_final_datasets(table_EP_full_text, table_PATSTAT)\n",
    "\n",
    "        wrap.set_plotting_style()\n",
    "        proportion_of_claims_available = wrap.plot_claim_data_availability(table_PATSTAT)\n",
    "        return proportion_of_claims_available\n",
    "    \n",
    "    def get_model_stats(step,mod):\n",
    "        \"\"\"Display summary statistics about the patents remaing in the data at each cleaning step\"\"\"\n",
    "\n",
    "        # numbers of patents in the dataset\n",
    "        a = len(mod.data['_table_main_patent_infos'][Config.VAR_APPLN_ID].unique().tolist())\n",
    "        #print('..Nb of patents:',a)\n",
    "\n",
    "        # number of patent families in the dataset\n",
    "        b = len(mod.data['_table_main_patent_infos'][Config.VAR_DOCDC_FAMILY_ID].unique().tolist())\n",
    "        #print('..Nb of patent families',b)\n",
    "\n",
    "        # average family citation per year count\n",
    "        c = mod.data['_table_main_patent_infos'][Config.NEW_VAR_NB_CITING_DOCDB_FAM_BY_YEAR].mean()\n",
    "        #print('..Average count of family citation per year:',c)\n",
    "\n",
    "        # availability of the patent claim data\n",
    "        df = mod.data.copy()\n",
    "\n",
    "        d = wrap.display_claims_availability(df)\n",
    "        #print('..Claim text availability', d)\n",
    "\n",
    "        return step,a, b, round(c,2) , str(round(d,2))+'%'\n",
    "    \n",
    "    def create_table_data_cleaning(model):\n",
    "\n",
    "        rows = []\n",
    "\n",
    "        rows.append(wrap.get_model_stats(\"Input dataset\", model))\n",
    "\n",
    "\n",
    "        # step1\n",
    "        model = DataCleaning._keep_only_EP_patents(model)\n",
    "        rows.append(wrap.get_model_stats('EP patents only', model))\n",
    "        # step 2\n",
    "        model = DataCleaning._select_time_range(model)\n",
    "        rows.append(wrap.get_model_stats('Select time range', model))\n",
    "        # step 3\n",
    "        model = DataCleaning._keep_only_granted_patents(model)\n",
    "        rows.append(wrap.get_model_stats('Granted patents only', model))\n",
    "        # step 4\n",
    "        model = DataCleaning._select_one_patent_per_family(model)\n",
    "        rows.append(wrap.get_model_stats('One patent per family', model))\n",
    "        # step 5\n",
    "        model = DataCleaning._select_breakthrough_patents(model)\n",
    "        rows.append(wrap.get_model_stats('Breakthrough patents', model))\n",
    "\n",
    "        df = pd.DataFrame(rows, columns=[\"step\",\"nb_patents\", \"nb_patent_fam\", \"av_count_fam_cit_per_year\", \"claim_text_availability\"])\n",
    "\n",
    "        return df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "#HTML(wrap.create_table_data_cleaning(model).to_html(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Add to the table above:**\n",
    "- Nb of clusters identified\n",
    "- Modularity\n",
    "- Content of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1\n",
    "model = DataCleaning._keep_only_EP_patents(model)\n",
    "# step 2\n",
    "#model = DataCleaning._select_time_range(model)\n",
    "# step 3\n",
    "#model = DataCleaning._keep_only_granted_patents(model)\n",
    "# step 4\n",
    "#model = DataCleaning._select_one_patent_per_family(model)\n",
    "# step 5\n",
    "#model = DataCleaning._select_breakthrough_patents(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "#model._data_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape in an OOP manner before building the network\n",
    "model._fit_to_object_oriented_design()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving all types of citations\n",
    "model._get_citations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search in the full text database the patents of interest\n",
    "model._get_full_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing, construction of the feature space and computation of all pairwise similarities\n",
    "model._text_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builing the NLP-based patent network\n",
    "model._build_patent_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualisation._draw_graph_with_communities(model);   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualisation._display_cluster_word_clouds(model);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
