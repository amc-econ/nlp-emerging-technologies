{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Co-citations etc to link patents are only made on the basis of the patents IN the sample. ex patent 1 and patent 2 are both cited by a bunch of other patents outside of the domain or the time frame. Solutions:\n",
    "- include \"extra-scope patents\"\n",
    "- enlarge the scope (probably better!)\n",
    "- and be careful with removing patents from the sample! (filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Preferring `dicts` over `lists` would allo`avoiding loops and improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We prefer `igraph` (written in C) over `networkx` (written in pure Python) for the sake of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Code and raw input data for all analyses, including generating the networks and figures, is also included in supplementary material. The code is also hosted on github.com at https://github.com/loujineamc/nlp_emerging_technologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ">The jupyter notebook and the OOP approach choosen complicate a bit the picture and the explanation, but it works well if the class and fonctions are well defined in the methodological part and run only before the results are displayed.\n",
    "\n",
    "> As a convention, we denote with `_` \"useful\" class methods and with `__` class methods that should not be called outside the class (ie. code snippets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Number the table of contents\n",
    "- Manage citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Work in progress:**\n",
    "- Reconstruction of the previous model with this coding framework (OOD with inheritance)\n",
    "- Filter a pandas df without creating a duplicate??\n",
    "- For the moment we select top patents only across years (and not sectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\">Introduction</a></span></li><li><span><a href=\"#Configuration\" data-toc-modified-id=\"Configuration-2\">Configuration</a></span></li><li><span><a href=\"#Loading-data\" data-toc-modified-id=\"Loading-data-3\">Loading data</a></span></li><li><span><a href=\"#Data-cleaning\" data-toc-modified-id=\"Data-cleaning-4\">Data cleaning</a></span></li><li><span><a href=\"#New-metrics\" data-toc-modified-id=\"New-metrics-5\">New metrics</a></span></li><li><span><a href=\"#Reshaping-to-OOP\" data-toc-modified-id=\"Reshaping-to-OOP-6\">Reshaping to OOP</a></span></li><li><span><a href=\"#Patent-object\" data-toc-modified-id=\"Patent-object-7\">Patent object</a></span></li><li><span><a href=\"#Get-citations\" data-toc-modified-id=\"Get-citations-8\">Get citations</a></span></li><li><span><a href=\"#Text-processing\" data-toc-modified-id=\"Text-processing-9\">Text processing</a></span></li><li><span><a href=\"#Building-the-network\" data-toc-modified-id=\"Building-the-network-10\">Building the network</a></span></li><li><span><a href=\"#Summary-statistics\" data-toc-modified-id=\"Summary-statistics-11\">Summary statistics</a></span></li><li><span><a href=\"#Visualisation\" data-toc-modified-id=\"Visualisation-12\">Visualisation</a></span></li><li><span><a href=\"#Core-modelling\" data-toc-modified-id=\"Core-modelling-13\">Core modelling</a></span></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-14\">Results</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-15\">References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying emerging technologies and understanding how they appear is a priority concern for policy-makers, since they can have “a revolutionary impact on the economy and society” <cite data-cite=\"7413608/BT7RDT4C\"></cite>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import warnings\n",
    "import igraph\n",
    "from igraph import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store all constants necessary to the model in a dedicated `Config` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration\"\"\"\n",
    "    \n",
    "    # Magic numbers\n",
    "    LAST_YEAR_TO_RECEIVE_CITAITONS = 2018\n",
    "    PERCENTAGE_TOP_PATENTS = 1\n",
    "\n",
    "    # PASTAT_variables \n",
    "    VAR_APPLN_ID = 'appln_id'\n",
    "    VAR_DOCDC_FAMILY_ID = 'docdb_family_id'\n",
    "    VAR_CITED_DOCDB_FAM_ID = 'cited_docdb_family_id'\n",
    "    VAR_APPLN_FILLING_YEAR = 'appln_filing_year'\n",
    "    VAR_NB_CITING_DOCDB_FAM = 'nb_citing_docdb_fam'\n",
    "    VAR_EARLIEST_FILLING_DATE = 'earliest_filing_date'\n",
    "    VAR_EARLIEST_FILING_YEAR = 'earliest_filing_year'\n",
    "\n",
    "    # Computed variables\n",
    "    NEW_VAR_CITING_DOCDB_FAM_IDS = 'citing_docdb_families_ids'\n",
    "    NEW_VAR_NB_CITING_DOCDB_FAM_BY_YEAR = 'nb_citing_docdb_fam_by_year'\n",
    "    \n",
    "    # add table names ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data previously extracted from PATSTAT with the custom engine and the query parameters. \n",
    "\n",
    "Patent data has been retrieved from the PATSTAT database of the Euro-pean Patent Office (EPO). PATSTAT contains bibliographical and legal status patent data from leading industrialised and developing countries. We extracted information on patent data in the EV battery technological field from the bulk EPO dabase, based on a list of CPC codes forming the EV battery technological landscape as established by the Joint Research Center (JRC) of the European Commission <cite data-cite=\"7413608/DEA3QPB8\"></cite>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files_prefix = \"wind_tech\"\n",
    "pre = '../data/raw/' + output_files_prefix\n",
    "suf = '.csv'\n",
    "        \n",
    "TABLE_MAIN_PATENT_INFOS = pd.read_csv(pre + '_table_main_patent_infos' + suf)\n",
    "TABLE_CPC = pd.read_csv(pre + '_table_cpc' + suf)\n",
    "TABLE_PATENTEES_INFO = pd.read_csv(pre + '_table_patentees_info' + suf)\n",
    "TABLE_DOCDB_BACKWARD_CITATIONS = pd.read_csv(pre + '_table_backward_docdb_citations' + suf)\n",
    "TABLE_DOCDB_FORWARD_CITATIONS = pd.read_csv(pre + '_table_forward_docdb_citations' + suf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we store all the data retrieved into a `data` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'_table_main_patent_infos': TABLE_MAIN_PATENT_INFOS,\n",
    "       '_table_cpc': TABLE_CPC, \n",
    "       '_table_patentees_info': TABLE_PATENTEES_INFO,\n",
    "       '_table_backward_docdb_citations': TABLE_DOCDB_BACKWARD_CITATIONS,\n",
    "       '_table_forward_docdb_citations': TABLE_DOCDB_FORWARD_CITATIONS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Correction for Japanese data\n",
    "- Normalisation over time\n",
    "- Keeping only one patent by DOCDB family\n",
    "- Filtering the data to keep only breakthrough patents (careful with rounding!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Provide rationale and explanation for the data cleaning part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following class `Data cleaning` contain the different steps of the data cleaning process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaning:\n",
    "    \"\"\"Data cleaning methods\"\"\"\n",
    "    \n",
    "    def __init__():\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _correct_JP_data(self):\n",
    "        \"\"\"Correction for Japanese patent data, in line with the literature\"\"\"\n",
    "        # Do # Update the list of ids\n",
    "        self = self.__update_patent_fam_ids() # Storing ids and filtering datasets\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _normalise(self):\n",
    "        \"\"\"Normalisation of the data accross years and sectors, to cater for **patent explosion**\"\"\"\n",
    "        # Do # Update the list of ids\n",
    "        self = self.__update_patent_fam_ids() # Storing ids and filtering datasets\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _select_one_patent_per_family(self):\n",
    "        \"\"\"In order to select only patent of interest, as well as saving computationnal power,\n",
    "        we select only the earliest patent by family\"\"\"\n",
    "        \n",
    "        # Local variables for simplicity\n",
    "        df_main = self.data['_table_main_patent_infos']\n",
    "        df_cpc = self.data['_table_cpc']\n",
    "        df_patentees = self.data['_table_patentees_info']\n",
    "        \n",
    "        # Filtering \n",
    "        df_main.sort_values(by = Config.VAR_EARLIEST_FILLING_DATE,inplace = True)\n",
    "        df_main.drop_duplicates(subset = [Config.VAR_DOCDC_FAMILY_ID],\n",
    "                                keep = 'first',\n",
    "                                inplace = True)\n",
    "        \n",
    "        # Storing ids and filtering datasets\n",
    "        self = self.__update_patent_fam_ids()   \n",
    "        return self\n",
    "    \n",
    "\n",
    "    def _select_breakthrough_patents(self):\n",
    "        \"\"\"Filtering the data to keep only breakthrough patents\"\"\"\n",
    "        \n",
    "        # Unpacking some variables for clarity\n",
    "        X = Config.PERCENTAGE_TOP_PATENTS\n",
    "        df = self.data['_table_main_patent_infos']\n",
    "        \n",
    "        # Selection  of the top patents\n",
    "        filtered_df = pd.DataFrame()\n",
    "        for year in df[Config.VAR_EARLIEST_FILING_YEAR].unique().tolist():\n",
    "            df_year = df[df[Config.VAR_EARLIEST_FILING_YEAR] == year]\n",
    "            df_year.sort_values(by = Config.VAR_NB_CITING_DOCDB_FAM, ascending = False, inplace = True)\n",
    "            nb_top_patent_given_year = int(math.ceil(X*len(df_year))) # Needs rounding up\n",
    "            df_year = df_year.head(nb_top_patent_given_year)\n",
    "            filtered_df = pd.concat([filtered_df, df_year])\n",
    "            \n",
    "        # Update the table and the list of patent/fam ids\n",
    "        self.data['_table_main_patent_infos'] = filtered_df\n",
    "        \n",
    "        # Storing ids and filtering datasets\n",
    "        self = self.__update_patent_fam_ids()\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def __update_patent_fam_ids(self):\n",
    "        \"\"\"\n",
    "        Storing patents ids and family ids and filtering the datasets\n",
    "        # Filtering the first 3 datasets on the list of patent ids \n",
    "        # Filtering the other 2 datasets on the list of family ids\n",
    "        \"\"\"\n",
    "        \n",
    "        # (1) Update the list of ids (patent ids and family ids)\n",
    "        df_main = self.data['_table_main_patent_infos']\n",
    "        self.patent_ids = df_main[Config.VAR_APPLN_ID].unique().tolist()\n",
    "        self.patent_family_ids = df_main[Config.VAR_DOCDC_FAMILY_ID].unique().tolist()\n",
    "        \n",
    "        # (2) Filter the tables according to the new list of patent ids\n",
    "        def __filter(df, var, list_ids):\n",
    "            \"\"\"Code snippet to filter a dataset according to a list of ids\"\"\"\n",
    "            condition = df[var].isin(list_ids)\n",
    "            return df[condition]\n",
    "        \n",
    "        for key in self.data:\n",
    "            if key in ['_table_main_patent_infos','_table_cpc','_table_patentees_info']:\n",
    "                self.data[key] = __filter(self.data[key], Config.VAR_APPLN_ID, self.patent_ids)\n",
    "            elif key in ['_table_backward_docdb_citations','_table_forward_docdb_citations']:\n",
    "                self.data[key] = __filter(self.data[key], Config.VAR_DOCDC_FAMILY_ID, self.patent_family_ids)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Number of DOCDB citations by year (to select breakthrough patents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewMetrics:\n",
    "    \"\"\"Methods to derive new metrics from the data\"\"\"\n",
    "    \n",
    "    def __init__():\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _get_DOCDB_fam_cites_per_year(self):\n",
    "        \"\"\"Adding a variable to keep track of yearly citations by patent family\"\"\"\n",
    "        \n",
    "        # Unpacking some variables for clarity\n",
    "        df = self.data['_table_main_patent_infos']\n",
    "        citations_by_year = Config.NEW_VAR_NB_CITING_DOCDB_FAM_BY_YEAR\n",
    "        citations_docdb_fam = Config.VAR_NB_CITING_DOCDB_FAM\n",
    "        year = Config.VAR_APPLN_FILLING_YEAR\n",
    "        ref_year = Config.LAST_YEAR_TO_RECEIVE_CITAITONS\n",
    "        \n",
    "        # Compute the metric\n",
    "        df[citations_by_year] = df[citations_docdb_fam]/(ref_year-df[year])\n",
    "        \n",
    "        # Updating the table\n",
    "        self.TABLE_ALL_PATENTS_INFO = df \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reshaping to OOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We define a set of methods to reshape the data from the tabular form (as extracted from PATSTAT) to an object oriented form, where patents are identified and attributes attributed to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Patent object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We create a patent object. Since the patent will have a long list of attributes, we stored their attributes in a dictionnary. As a shortcut, we store the main patent key `appln_id` as an attribute direclty accesible with `patent.appln_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Patent:\n",
    "    \"\"\"1 patent = 1 patent object\"\"\"\n",
    "    \n",
    "    # Attributes\n",
    "    patent_attributes = {} # Contains the list of the patent's attributes\n",
    "    appln_id:int # as a shortcut we  store the main patent key\n",
    "    \n",
    "    def __init__(self, appln_id):\n",
    "        \"\"\"Setting the patent parameters\"\"\"\n",
    "        self.patent_attributes.update({Config.VAR_APPLN_ID :  appln_id})\n",
    "        self.appln_id = appln_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class ReshapingToOOP:\n",
    "    \"\"\"Methods to assign the data to patent objects\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _create_patent_objects(self):\n",
    "        \"\"\"\n",
    "        Create a Patent object for each patent id and store them in a list\n",
    "        \"\"\"\n",
    "        self.patent_list = []\n",
    "        for patent_id in list(self.patent_ids):\n",
    "            a = Patent(patent_id)\n",
    "            self.patent_list.append(a)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _assign_data_to_patent_obj(self):\n",
    "        \"\"\"\n",
    "        Once the data has been retrieved from PATSTAT and the patent objects have been created,\n",
    "        we assign the data to the Patent objects\n",
    "        \"\"\"\n",
    "        \n",
    "        def __snippet_store_patent_attributes(table):\n",
    "            \"\"\"\n",
    "            Code snippet to dynamically store attributes \n",
    "            from a Pandas table in a dictionnary\n",
    "            # If a value has several values, then ts stored in a list\n",
    "            \"\"\"\n",
    "            a = {}\n",
    "            for col in list(table):\n",
    "                key = col\n",
    "                value = table[col].unique().tolist()#[0]\n",
    "                value = [x for x in value if (x == x)!=False]  # new line\n",
    "                if len(value) == 1:\n",
    "                    value = value[0]\n",
    "                a[key] = value\n",
    "            return a\n",
    "        \n",
    "        # Unpacking some variables\n",
    "        df_main = self.data['_table_main_patent_infos']\n",
    "        df_cpc = self.data['_table_cpc']\n",
    "        df_patentee = self.data['_table_patentees_info']\n",
    "        df_bwd = self.data['_table_backward_docdb_citations']\n",
    "        df_fwd = self.data['_table_forward_docdb_citations']\n",
    "        \n",
    "        # (1) Assigning the data contained in the main table to the patent\n",
    "        # We merge backward citation data to the main table (on family id)\n",
    "        key = Config.VAR_DOCDC_FAMILY_ID\n",
    "        df_main = pd.merge(df_main, df_bwd,how = 'left',left_on = key,right_on = key)\n",
    "        \n",
    "        for patent in self.patent_list:\n",
    "            for df in [df_main, df_cpc, df_patentee]:    \n",
    "                patent_table = df[df[Config.VAR_APPLN_ID]==patent.appln_id]\n",
    "                d = __snippet_store_patent_attributes(table = patent_table)\n",
    "                patent.patent_attributes.update(d)\n",
    "        \n",
    "        # (2) Assigning forward citations to the patents      \n",
    "        df_fwd.columns = ['A','B','C'] # Random column names\n",
    "        for patent in self.patent_list:\n",
    "            patent_fam_table = df_fwd[df_fwd['A']==patent.patent_attributes[Config.VAR_DOCDC_FAMILY_ID]]\n",
    "            citing_fam = patent_fam_table['B'].unique().tolist()\n",
    "            patent.patent_attributes.update({Config.NEW_VAR_CITING_DOCDB_FAM_IDS :citing_fam})\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Get citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We use the similarity measure to link the patents in the network. We use direct and indirect citation links:\n",
    "􏰀\n",
    "- Direct backwards citation (at the patent family level); 􏰀 \n",
    "- Co-citations (CC);\n",
    "- Biographic coupling (BC);\n",
    "- Longitudinal coupling (LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class GetCitations:\n",
    "    \"\"\"Methods to compute direct and indirect (BC, CC, LC) citations between the patents\"\"\"\n",
    "        \n",
    "    def _get_direct_citations(self):\n",
    "        \"\"\"Get direct backwards citations (at the level of the family level)\"\"\"\n",
    "        \n",
    "        # Unpacking some varibles for clarity\n",
    "        fam = Config.VAR_DOCDC_FAMILY_ID\n",
    "        cited_fam = Config.VAR_CITED_DOCDB_FAM_ID\n",
    "            \n",
    "        # (1) If a patent cites only one family\n",
    "        list1 = [(x,y) for x in self.patent_list for y in self.patent_list \\\n",
    "                 if y.patent_attributes[fam] == x.patent_attributes[cited_fam]]\n",
    "        \n",
    "        # (2) If the patent cites several families (then stored as list)\n",
    "        list2 = [(x,y) for x in self.patent_list for y in self.patent_list \\\n",
    "                 if type(x.patent_attributes[cited_fam]) ==list \\\n",
    "                 if y.patent_attributes[fam] in x.patent_attributes[cited_fam]]\n",
    "        \n",
    "        # Concatenating the two lists to have the direct citations\n",
    "        self.direct_citations = list1 + list2\n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def _get_BC_citations(self):\n",
    "        \"\"\"\n",
    "        # (1) Bibliographic coupling occurs when two works reference a common third work\n",
    "        # (2) The produced list is non directed.\n",
    "        # (3) Can be optimised\n",
    "        \"\"\"\n",
    "            \n",
    "        # Definition of variables\n",
    "        BC = []\n",
    "        a = self.patent_list\n",
    "        all_patent_pairs = [(a[p1], a[p2]) for p1 in range(len(a)) for p2 in range(p1+1,len(a))]\n",
    "\n",
    "        # Computing BC by looping over all pairs of patents\n",
    "        for patent_1, patent_2 in all_patent_pairs:\n",
    "            list_citing_1 = patent_1.patent_attributes[Config.NEW_VAR_CITING_DOCDB_FAM_IDS]\n",
    "            list_citing_2 = patent_2.patent_attributes[Config.NEW_VAR_CITING_DOCDB_FAM_IDS]\n",
    "            common_elements = [x for x in list_citing_1 if x in list_citing_2]\n",
    "            if len(common_elements)>0:\n",
    "                BC.append((patent_1, patent_2))\n",
    "            \n",
    "        # Removing duplicated items in the list\n",
    "        self.BC = list(set(BC)) \n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def _get_CC_citations(self):\n",
    "        \"\"\"\n",
    "        # (1) Co-citation is defined as the frequency with which two documents are cited together\n",
    "        by other documents. If at least one other document cites two documents in common these documents\n",
    "        are said to be co-cited\n",
    "        # (2) The produced list is non directed\n",
    "        \"\"\"\n",
    "        CC = []\n",
    "            \n",
    "        # Definition of all patent pairs\n",
    "        a = self.patent_list\n",
    "        all_patent_pairs = [(a[p1], a[p2]) for p1 in range(len(a)) for p2 in range(p1+1,len(a))]\n",
    "            \n",
    "        # Definition of the search algorithm\n",
    "        for patent in self.patent_list:\n",
    "            a = patent.patent_attributes[Config.VAR_CITED_DOCDB_FAM_ID]\n",
    "            if type(a)==list:\n",
    "                if len(a)>1:\n",
    "                    all_cited_patent_pairs = [(a[p1], a[p2]) \\\n",
    "                                              for p1 in range(len(a)) \\\n",
    "                                              for p2 in range(p1+1,len(a))]\n",
    "                    for pair in all_cited_patent_pairs:\n",
    "                        CC.append(pair)\n",
    "        \n",
    "        pairs = list(set(CC)) \n",
    "        \n",
    "        CC = []\n",
    "        for pair in pairs:\n",
    "            patent1 = [patent \\\n",
    "                       for patent in self.patent_list \\\n",
    "                       if patent.patent_attributes[Config.VAR_DOCDC_FAMILY_ID] == pair[0]]\n",
    "            patent2 = [patent \\\n",
    "                       for patent in self.patent_list \\\n",
    "                       if patent.patent_attributes[Config.VAR_DOCDC_FAMILY_ID] == pair[1]]\n",
    "\n",
    "            if len(patent1)>0:\n",
    "                patent1 = patent1[0]\n",
    "            else: patent1=np.nan\n",
    "\n",
    "            if len(patent2)>0:\n",
    "                patent2 = patent2[0]\n",
    "            else: patent2=np.nan\n",
    "\n",
    "            pair = (patent1, patent2)\n",
    "            CC.append(pair)\n",
    "\n",
    "        self.CC = [pair for pair in CC if (pair[0]==pair[0]) & (pair[1] == pair[1])]\n",
    "        return self\n",
    "     \n",
    "        \n",
    "    def _get_LC_citations(self):\n",
    "        \"\"\"\n",
    "        # (1) LC (longitudinal coupling). A cites a document that cites B\n",
    "        # (2) The produced list IS directed \n",
    "        # (3) Can be optimised\n",
    "        \"\"\"          \n",
    "        LC = []\n",
    "            \n",
    "        # Identifying all patents cited by a given patent A\n",
    "        for patent_A in self.patent_list:\n",
    "            cited_fam = patent_A.patent_attributes[Config.VAR_CITED_DOCDB_FAM_ID]\n",
    "            if type(cited_fam)==float:\n",
    "                    cited_fam = []\n",
    "                    cited_fam.append(patent_A.patent_attributes[Config.VAR_CITED_DOCDB_FAM_ID])\n",
    "            cited_patents = [patent \\\n",
    "                             for patent in self.patent_list \\\n",
    "                             if patent.patent_attributes[Config.VAR_DOCDC_FAMILY_ID] in cited_fam]\n",
    "                \n",
    "            # Identifying all patents cited by a patent cited by patent A\n",
    "            for cited_patent in cited_patents:\n",
    "                cited_fam = cited_patent.patent_attributes[Config.VAR_CITED_DOCDB_FAM_ID]\n",
    "                if type(cited_fam)==float:\n",
    "                    cited_fam = []\n",
    "                    cited_fam.append(cited_patent.patent_attributes[Config.VAR_CITED_DOCDB_FAM_ID])\n",
    "                cited_cited_patents = [patent \\\n",
    "                                       for patent in self.patent_list \\\n",
    "                                       if patent.patent_attributes[Config.VAR_DOCDC_FAMILY_ID] in cited_fam]\n",
    "                    \n",
    "                # Adding the pairs in the LC list\n",
    "                for patent_B in cited_cited_patents:\n",
    "                    LC.append((patent_A, patent_B))\n",
    "                    \n",
    "        # Removing duplicated items in the LC list\n",
    "        self.LC = list(set(LC)) \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- stemming\n",
    "- vectorisation with TF-IDF\n",
    "- measure cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class TextProcessing:\n",
    "    \"\"\"\n",
    "    Methods for text analysis and similarity measures\n",
    "    For the sake of computational power, we use these methods for patents in a citations pair only \n",
    "    \"\"\"\n",
    "    \n",
    "    def _stemming():\n",
    "        \"\"\"Reducing words to their stem word (semantic root)\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _vectorize():\n",
    "        \"\"\"Vectorise the patents in a high dimention space\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _measure_cosine_similarity(pair):\n",
    "        \"\"\"Measure the similiarity between a pair of linked patents pair = (p1, p2)\"\"\"\n",
    "        return 1 # for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildNetwork():\n",
    "    \"\"\"Builds a weighted network based on backwards citations and text similarity\"\"\"\n",
    "    \n",
    "    def _create_network(self):\n",
    "        \"\"\"Create the weighted and undirected network with igraph\"\"\"\n",
    "        \n",
    "        def __create_patent_dict(patent_list):\n",
    "            \"\"\"Code snippet to store the patents in a patent dictionnary\n",
    "            {id, patent object}\"\"\"\n",
    "            patent_dict = {}\n",
    "            for patent in patent_list:\n",
    "                pair = {patent.appln_id: patent}\n",
    "                patent_dict.update(pair)\n",
    "            return patent_dict\n",
    "        \n",
    "        # Creation of the dictionnary (to avoid looping over the list afterwards)\n",
    "        patent_dict = __create_patent_dict(self.patent_list)\n",
    "        \n",
    "        list_edges = []\n",
    "        \n",
    "        for pair in self.direct_citations:\n",
    "            similarity = _measure_cosine_similarity(pair)\n",
    "            patent1 = patent_dict.get(pair[0])\n",
    "            patent2 = patent_dict.get(pair[1])\n",
    "            weighted_edge = (patent1, patent2, similarity) # weight = text cosine similarity\n",
    "            list_edges.append(weighted_edge)\n",
    "        \n",
    "        # We have to pack the edges in a list like this\n",
    "        #list_edges = [(\"a\", \"b\", 3.0), (\"c\", \"d\", 4.0), (\"a\", \"c\", 5.0)]\n",
    "        \n",
    "        \n",
    "        self.graph = Graph.TupleList(list_edges, weights=True)\n",
    "        \n",
    "        # toy graph\n",
    "        #self.graph = Graph.Erdos_Renyi(75,.01)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryStatistics:\n",
    "    \"\"\"Summary statistics for the data section\"\"\"\n",
    "    # Can also help comparing before data cleaning and after!\n",
    "    \n",
    "    def _print_nb_patents(self):\n",
    "        \"\"\"Printing info\"\"\"\n",
    "        print('..Nb of patents:',len(self.data['_table_main_patent_infos']\\\n",
    "                                     [Config.VAR_APPLN_ID].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualisation:\n",
    "    \"\"\"Visualisation methods\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Core modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class Model(Config, DataCleaning, NewMetrics, ReshapingToOOP, GetCitations,\n",
    "            TextProcessing, BuildNetwork, SummaryStatistics, Visualisation):\n",
    "    \"\"\"Creation of a model which inherits several building blocks\"\"\"\n",
    "    \n",
    "    # Attributes of the model\n",
    "    \n",
    "    data: dict # datasets\n",
    "    patent_list: list # patent objects\n",
    "    patent_ids: list # list of patent ids contained in the model\n",
    "    patent_family_ids: list # list of DOCDB family ids contained in the model\n",
    "    direct_citations: list # directed list of simple citations\n",
    "    CC: list # undirected list of co-citations\n",
    "    BC: list # undirected list of bibliographical coupling\n",
    "    LC: list # directed list of longitudinal citations\n",
    "    graph: igraph.Graph # Igraph network\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _input_data(self, data):\n",
    "        \"\"\"Getting the data in the model\"\"\"\n",
    "        self.data = data\n",
    "        \n",
    "    \n",
    "    def _compute_new_metrics(self):\n",
    "        \"\"\"Adding new variables in the dataset\"\"\"\n",
    "        self = NewMetrics._get_DOCDB_fam_cites_per_year(self)\n",
    "    \n",
    "        \n",
    "    def _data_cleaning(self):\n",
    "        \"\"\"Data cleaning using the DataCleaning class methods\"\"\"\n",
    "        self = DataCleaning._correct_JP_data(self)\n",
    "        self = DataCleaning._normalise(self)\n",
    "        self = DataCleaning._select_one_patent_per_family(self)\n",
    "        self = DataCleaning._select_breakthrough_patents(self)\n",
    "        \n",
    "        \n",
    "    def _fit_to_object_oriented_design(self):\n",
    "        \"\"\"We reshape the data from a tabular form to an object oriented form\"\"\"\n",
    "        self = ReshapingToOOP._create_patent_objects(self)\n",
    "        self = ReshapingToOOP._assign_data_to_patent_obj(self)\n",
    "    \n",
    "    \n",
    "    def _get_citations(self):\n",
    "        \"\"\"Identify direct and indirect citations that link the patents\"\"\"\n",
    "        self = GetCitations._get_direct_citations(self)\n",
    "        self = GetCitations._get_CC_citations(self)\n",
    "        self = GetCitations._get_BC_citations(self)\n",
    "        self = GetCitations._get_LC_citations(self)\n",
    "    \n",
    "    \n",
    "    def _compute_text_similarity(self):\n",
    "        \"\"\"Computing text similarities between linked patents\"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _build_patent_network(self):\n",
    "        \"\"\"We build the patent network (weighted directed graph)\"\"\"\n",
    "        self = BuildNetwork._create_network(self)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model._input_data(data)\n",
    "model._compute_new_metrics()\n",
    "model._data_cleaning()\n",
    "model._fit_to_object_oriented_design()\n",
    "model._get_citations()\n",
    "model._build_patent_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.CC ## is it because of the sample or it does not work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.graph.vcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.graph.ecount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Error at /project/vendor/source/igraph/src/layout_kk.c:93: `K' constant must be positive in Kamada-Kawai layout, Invalid value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/igraph/drawing/__init__.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcairo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m# Plot the graph on this context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mredraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;31m# No idea why this is needed but python crashes without\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/igraph/drawing/__init__.py\u001b[0m in \u001b[0;36mredraw\u001b[0;34m(self, context)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mplotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mopacity\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_group_to_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/igraph/clustering.py\u001b[0m in \u001b[0;36m__plot__\u001b[0;34m(self, context, bbox, palette, *args, **kwds)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vertex_color\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmembership\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__plot__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_formatted_cluster_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/igraph/__init__.py\u001b[0m in \u001b[0;36m__plot__\u001b[0;34m(self, context, bbox, palette, *args, **kwds)\u001b[0m\n\u001b[1;32m   3357\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"drawer_factory\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3358\u001b[0m         \u001b[0mdrawer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrawer_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3359\u001b[0;31m         \u001b[0mdrawer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/igraph/drawing/graph.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, graph, palette, *args, **kwds)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Calculate/get the layout of the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mlayout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layout\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Determine the size of the margin on each side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/igraph/drawing/graph.py\u001b[0m in \u001b[0;36mensure_layout\u001b[0;34m(self, layout, graph)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mlayout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlayout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mlayout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mlayout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/igraph/__init__.py\u001b[0m in \u001b[0;36mlayout\u001b[0;34m(self, layout, *args, **kwds)\u001b[0m\n\u001b[1;32m   1559\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layout method must be callable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1561\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/igraph/__init__.py\u001b[0m in \u001b[0;36mlayout_auto\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m   1629\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m             \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"drl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlayout_grid_fruchterman_reingold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/igraph/__init__.py\u001b[0m in \u001b[0;36mlayout\u001b[0;34m(self, layout, *args, **kwds)\u001b[0m\n\u001b[1;32m   1559\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layout method must be callable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1561\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/igraph/__init__.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m   4220\u001b[0m     \"\"\"\n\u001b[1;32m   4221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4222\u001b[0;31m         \u001b[0mlayout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4224\u001b[0m             \u001b[0mlayout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Error at /project/vendor/source/igraph/src/layout_kk.c:93: `K' constant must be positive in Kamada-Kawai layout, Invalid value"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<igraph.drawing.Plot at 0x7f275aa5bf28>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comms = model.graph.community_multilevel()\n",
    "plot(comms, mark_groups = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"cite2c-biblio\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "7413608/6JNXYN6Y": {
     "DOI": "10.1016/j.respol.2017.06.006",
     "URL": "http://www.sciencedirect.com/science/article/pii/S0048733317301038",
     "abstract": "Research which explores unchartered waters has a high potential for major impact but also carries a higher uncertainty of having impact. Such explorative research is often described as taking a novel approach. This study examines the complex relationship between pursuing a novel approach and impact. Viewing scientific research as a combinatorial process, we measure novelty in science by examining whether a published paper makes first-time-ever combinations of referenced journals, taking into account the difficulty of making such combinations. We apply this newly developed measure of novelty to all Web of Science research articles published in 2001 across all scientific disciplines. We find that highly novel papers, defined to be those that make more (distant) new combinations, deliver high gains to science: they are more likely to be a top 1% highly cited paper in the long run, to inspire follow-on highly cited research, and to be cited in a broader set of disciplines and in disciplines that are more distant from their “home” field. At the same time, novel research is also more risky, reflected by a higher variance in its citation performance. We also find strong evidence of delayed recognition of novel papers as novel papers are less likely to be top cited when using short time-windows. In addition, we find that novel research is significantly more highly cited in “foreign” fields but not in their “home” field. Finally, novel papers are published in journals with a lower Impact Factor, compared with non-novel papers, ceteris paribus. These findings suggest that science policy, in particular funding decisions which rely on bibliometric indicators based on short-term citation counts and Journal Impact Factors, may be biased against “high risk/high gain” novel research. The findings also caution against a mono-disciplinary approach in peer review to assess the true value of novel research.",
     "accessed": {
      "day": 2,
      "month": 2,
      "year": 2020
     },
     "author": [
      {
       "family": "Wang",
       "given": "Jian"
      },
      {
       "family": "Veugelers",
       "given": "Reinhilde"
      },
      {
       "family": "Stephan",
       "given": "Paula"
      }
     ],
     "container-title": "Research Policy",
     "container-title-short": "Research Policy",
     "id": "7413608/6JNXYN6Y",
     "issue": "8",
     "issued": {
      "day": 1,
      "month": 10,
      "year": 2017
     },
     "journalAbbreviation": "Research Policy",
     "language": "en",
     "page": "1416-1436",
     "page-first": "1416",
     "shortTitle": "Bias against novelty in science",
     "title": "Bias against novelty in science: A cautionary tale for users of bibliometric indicators",
     "title-short": "Bias against novelty in science",
     "type": "article-journal",
     "volume": "46"
    },
    "7413608/BT7RDT4C": {
     "DOI": "10.1080/09537329508524202",
     "URL": "http://sro.sussex.ac.uk/id/eprint/26547/",
     "accessed": {
      "day": 20,
      "month": 7,
      "year": 2020
     },
     "author": [
      {
       "family": "Martin",
       "given": "Ben R."
      }
     ],
     "container-title": "Technology Analysis and Strategic Management",
     "id": "7413608/BT7RDT4C",
     "issue": "2",
     "issued": {
      "year": 1995
     },
     "page": "139-68",
     "page-first": "139",
     "title": "Foresight in science and technology",
     "type": "article-journal",
     "volume": "7"
    },
    "7413608/DEA3QPB8": {
     "URL": "https://scholar.google.fr/scholar?q=Monitoring+R%26I+in+Low-Carbon+Energy+Technologies&hl=fr&as_sdt=0&as_vis=1&oi=scholart",
     "accessed": {
      "day": 23,
      "month": 2,
      "year": 2020
     },
     "id": "7413608/DEA3QPB8",
     "title": "Monitoring R&I in Low-Carbon Energy Technologies - Google Scholar",
     "type": "article"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
