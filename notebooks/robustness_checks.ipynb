{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of emerging technologies using NLP-powered patent networks\n",
    "\n",
    "## Robustness checks\n",
    "\n",
    "> Author: **Antoine MATHIEU COLLIN**\n",
    "* Department of Management, Strategy and Innovation (MSI) of the Faculty of Economics and Business (FEB), KU Leuven\n",
    "* Department of Computer Science of the Faculty of Engineering Science, KU Leuven\n",
    "* Leuven.AI, KU Leuven Institute for Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 1. Loading the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# location of the PATSTAT data previously retrieved with the data_extraction_from_PATSTAT.ipynb notebook\n",
    "output_files_prefix = \"wind_tech_1990_2020_with_publications\"\n",
    "pre = '../data/raw/' + output_files_prefix\n",
    "suf = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# for convenience, we store all the data retrieved into a single data object.\n",
    "data = {'_table_main_patent_infos': pd.read_csv(pre + '_table_main_patent_infos' + suf, low_memory=False),\n",
    "       '_table_cpc': pd.read_csv(pre + '_table_cpc' + suf, low_memory=False), \n",
    "       '_table_patentees_info': pd.read_csv(pre + '_table_patentees_info' + suf, low_memory=False),\n",
    "       '_table_backward_docdb_citations': pd.read_csv(pre + '_table_backward_docdb_citations' + suf, low_memory=False),\n",
    "       '_table_forward_docdb_citations': pd.read_csv(pre + '_table_forward_docdb_citations' + suf, low_memory=False),\n",
    "       '_text_data':pd.read_csv('../data/raw/wind_tech_1990_2020_with_publications_full_text.csv', sep = ',')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>appln_id</th>\n",
       "      <th>appln_id.1</th>\n",
       "      <th>appln_auth</th>\n",
       "      <th>appln_nr</th>\n",
       "      <th>appln_kind</th>\n",
       "      <th>appln_filing_date</th>\n",
       "      <th>appln_filing_year</th>\n",
       "      <th>appln_nr_epodoc</th>\n",
       "      <th>appln_nr_original</th>\n",
       "      <th>...</th>\n",
       "      <th>pat_publn_id</th>\n",
       "      <th>publn_auth</th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>publn_nr_original</th>\n",
       "      <th>publn_kind</th>\n",
       "      <th>appln_id.6</th>\n",
       "      <th>publn_date</th>\n",
       "      <th>publn_lg</th>\n",
       "      <th>publn_first_grant</th>\n",
       "      <th>publn_claims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>EP</td>\n",
       "      <td>07015148</td>\n",
       "      <td>A</td>\n",
       "      <td>2007-08-02</td>\n",
       "      <td>2007</td>\n",
       "      <td>EP20070015148</td>\n",
       "      <td>07015148</td>\n",
       "      <td>...</td>\n",
       "      <td>278556884</td>\n",
       "      <td>EP</td>\n",
       "      <td>1892412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1</td>\n",
       "      <td>146</td>\n",
       "      <td>2008-02-27</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>EP</td>\n",
       "      <td>07015148</td>\n",
       "      <td>A</td>\n",
       "      <td>2007-08-02</td>\n",
       "      <td>2007</td>\n",
       "      <td>EP20070015148</td>\n",
       "      <td>07015148</td>\n",
       "      <td>...</td>\n",
       "      <td>278556884</td>\n",
       "      <td>EP</td>\n",
       "      <td>1892412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1</td>\n",
       "      <td>146</td>\n",
       "      <td>2008-02-27</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>EP</td>\n",
       "      <td>07015148</td>\n",
       "      <td>A</td>\n",
       "      <td>2007-08-02</td>\n",
       "      <td>2007</td>\n",
       "      <td>EP20070015148</td>\n",
       "      <td>07015148</td>\n",
       "      <td>...</td>\n",
       "      <td>278556884</td>\n",
       "      <td>EP</td>\n",
       "      <td>1892412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1</td>\n",
       "      <td>146</td>\n",
       "      <td>2008-02-27</td>\n",
       "      <td>de</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>EP</td>\n",
       "      <td>07015148</td>\n",
       "      <td>A</td>\n",
       "      <td>2007-08-02</td>\n",
       "      <td>2007</td>\n",
       "      <td>EP20070015148</td>\n",
       "      <td>07015148</td>\n",
       "      <td>...</td>\n",
       "      <td>335943971</td>\n",
       "      <td>EP</td>\n",
       "      <td>1892412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B1</td>\n",
       "      <td>146</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>de</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>EP</td>\n",
       "      <td>07015148</td>\n",
       "      <td>A</td>\n",
       "      <td>2007-08-02</td>\n",
       "      <td>2007</td>\n",
       "      <td>EP20070015148</td>\n",
       "      <td>07015148</td>\n",
       "      <td>...</td>\n",
       "      <td>335943971</td>\n",
       "      <td>EP</td>\n",
       "      <td>1892412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B1</td>\n",
       "      <td>146</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>de</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  appln_id  appln_id.1 appln_auth  appln_nr appln_kind  \\\n",
       "0      0       146         146         EP  07015148         A    \n",
       "1      0       146         146         EP  07015148         A    \n",
       "2      0       146         146         EP  07015148         A    \n",
       "3      0       146         146         EP  07015148         A    \n",
       "4      0       146         146         EP  07015148         A    \n",
       "\n",
       "  appln_filing_date  appln_filing_year appln_nr_epodoc appln_nr_original  ...  \\\n",
       "0        2007-08-02               2007   EP20070015148          07015148  ...   \n",
       "1        2007-08-02               2007   EP20070015148          07015148  ...   \n",
       "2        2007-08-02               2007   EP20070015148          07015148  ...   \n",
       "3        2007-08-02               2007   EP20070015148          07015148  ...   \n",
       "4        2007-08-02               2007   EP20070015148          07015148  ...   \n",
       "\n",
       "  pat_publn_id publn_auth  publn_nr publn_nr_original publn_kind appln_id.6  \\\n",
       "0    278556884         EP   1892412               NaN         A1        146   \n",
       "1    278556884         EP   1892412               NaN         A1        146   \n",
       "2    278556884         EP   1892412               NaN         A1        146   \n",
       "3    335943971         EP   1892412               NaN         B1        146   \n",
       "4    335943971         EP   1892412               NaN         B1        146   \n",
       "\n",
       "   publn_date  publn_lg  publn_first_grant publn_claims  \n",
       "0  2008-02-27        de                  0            7  \n",
       "1  2008-02-27        de                  0            7  \n",
       "2  2008-02-27        de                  0            7  \n",
       "3  2011-07-27        de                  1            6  \n",
       "4  2011-07-27        de                  1            6  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['_table_main_patent_infos'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run model_API.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Robutness checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data cleaning statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiation of the model\n",
    "model = Model()\n",
    "# fitting the model to the data\n",
    "model._input_data(data)\n",
    "# new metrics\n",
    "model._compute_new_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     10,
     99,
     115,
     133,
     141,
     146,
     159,
     165,
     180,
     193,
     216
    ]
   },
   "outputs": [],
   "source": [
    "class wrap:\n",
    "    \"\"\"\n",
    "    Creates a table with, for each data cleaning step:\n",
    "    - Nb of patents\n",
    "    - Nb of patent families\n",
    "    - Average count of famility citations\n",
    "    - Proportion of patents for which the claim text data is available\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def select_columns(data):\n",
    "        \"\"\"We remove the columns called 'index' as they are unuseful and perturb the merge\"\"\"\n",
    "\n",
    "        cols = ['appln_id',\n",
    "                'appln_auth',\n",
    "                'appln_nr',\n",
    "                'appln_kind',\n",
    "                'appln_filing_date',\n",
    "                'appln_filing_year',\n",
    "                'appln_nr_epodoc',\n",
    "                'appln_nr_original',\n",
    "                'ipr_type',\n",
    "                'receiving_office',\n",
    "                'internat_appln_id',\n",
    "                'int_phase',\n",
    "                'reg_phase',\n",
    "                'nat_phase',\n",
    "                'earliest_filing_date',\n",
    "                'earliest_filing_year',\n",
    "                'earliest_filing_id',\n",
    "                'earliest_publn_date',\n",
    "                'earliest_publn_year',\n",
    "                'earliest_pat_publn_id',\n",
    "                'granted',\n",
    "                'docdb_family_id',\n",
    "                'inpadoc_family_id',\n",
    "                'docdb_family_size',\n",
    "                'nb_citing_docdb_fam',\n",
    "                'nb_applicants',\n",
    "                'nb_inventors',\n",
    "                'appln_title_lg',\n",
    "                'appln_title',\n",
    "                'appln_abstract_lg',\n",
    "                'appln_abstract',\n",
    "                'ipc_class_symbol',\n",
    "                'ipc_class_level',\n",
    "                'ipc_version',\n",
    "                'ipc_value',\n",
    "                'ipc_position',\n",
    "                'ipc_gener_auth',\n",
    "                'nace2_code',\n",
    "                'weight',\n",
    "                'pat_publn_id',\n",
    "                'publn_auth',\n",
    "                'publn_nr',\n",
    "                'publn_nr_original',\n",
    "                'publn_kind',\n",
    "                'publn_date',\n",
    "                'publn_lg',\n",
    "                'publn_first_grant',\n",
    "                'publn_claims']\n",
    "\n",
    "        data['_table_main_patent_infos'] = data['_table_main_patent_infos'][cols]\n",
    "\n",
    "        cols = ['appln_id',\n",
    "                'person_id',\n",
    "                'applt_seq_nr',\n",
    "                'invt_seq_nr',\n",
    "                'person_name',\n",
    "                'person_address',\n",
    "                'person_ctry_code',\n",
    "                'doc_std_name_id',\n",
    "                'doc_std_name',\n",
    "                'psn_id',\n",
    "                'psn_name',\n",
    "                'psn_level',\n",
    "                'psn_sector',\n",
    "                'person_orig_id',\n",
    "                'source',\n",
    "                'source_version',\n",
    "                'name_freeform',\n",
    "                'last_name',\n",
    "                'first_name',\n",
    "                'middle_name',\n",
    "                'address_freeform',\n",
    "                'address_1',\n",
    "                'address_2',\n",
    "                'address_3',\n",
    "                'address_4',\n",
    "                'address_5',\n",
    "                'street',\n",
    "                'city',\n",
    "                'zip_code',\n",
    "                'state',\n",
    "                'residence_ctry_code',\n",
    "                'role']\n",
    "        data['_table_patentees_info'] = data['_table_patentees_info'][cols]\n",
    "        return data\n",
    "\n",
    "    def reshape_PATSTAT_data(data):\n",
    "        \"\"\" Reshaping PATSTAT data \"\"\"\n",
    "\n",
    "        # retrieve variables of interest from the PATSTAT dataset\n",
    "        cols = ['appln_id','appln_filing_year','appln_auth','publn_auth',\n",
    "                'publn_nr','publn_nr_original','publn_lg']\n",
    "\n",
    "        table_PATSTAT = data['_table_main_patent_infos']\n",
    "        cols = [col for col in list(table_PATSTAT) if col != 'publn_nr' and col != 'publn_nr_original']\n",
    "\n",
    "        table_PATSTAT = pd.melt(table_PATSTAT,\n",
    "                                id_vars=cols,\n",
    "                                var_name='type_publication_nb',\n",
    "                                value_name='publn_nr')\n",
    "        return table_PATSTAT\n",
    "    \n",
    "    def reshape_EP_full_text_data(data):\n",
    "        \"\"\" Reshapes the EP full text data to be able to assess the wether a PATSTAT patent is present\n",
    "        in the database \"\"\"\n",
    "\n",
    "        # retrieve variables of interest from the EP full text data\n",
    "        table_EP_full_text = data['_text_data']\n",
    "        # renaming the publication number column to align with PATSTAT before merging\n",
    "        table_EP_full_text.rename(columns={'publication_number':  'publn_nr'}, inplace = True)\n",
    "        # keep only patent which contains claims\n",
    "        condition = table_EP_full_text['text_type'] == 'CLAIM'\n",
    "        table_EP_full_text = table_EP_full_text[condition]\n",
    "        # drop duplicates and keep only 2 variables\n",
    "        table_EP_full_text = table_EP_full_text[['publn_nr', 'text_type']]\n",
    "        table_EP_full_text.drop_duplicates(inplace = True)\n",
    "        # store the ids as str\n",
    "        table_EP_full_text['publn_nr'] = table_EP_full_text['publn_nr'].astype(str)\n",
    "        return table_EP_full_text\n",
    "    \n",
    "    def add_citations(data, table_PATSTAT):\n",
    "        \"\"\"Adds the citation count to the data\"\"\"\n",
    "\n",
    "        df = data['_table_main_patent_infos']\n",
    "        mapp = dict(zip(df['appln_id'],df['nb_citing_docdb_fam']))\n",
    "        table_PATSTAT['nb_citing_docdb_fam'] = table_PATSTAT['appln_id'].map(mapp)\n",
    "        return table_PATSTAT\n",
    "    \n",
    "    def merge_data(data):\n",
    "        return pd.merge(left = data['_table_main_patent_infos'],\n",
    "                        right = data['_table_patentees_info'],\n",
    "                        on='appln_id')\n",
    "    \n",
    "    def merge_final_datasets(table_EP_full_text, table_PATSTAT):\n",
    "    \n",
    "        # merging the two datasets \n",
    "        mapp = dict(zip(table_EP_full_text['publn_nr'],table_EP_full_text['text_type']))\n",
    "        table_PATSTAT['claims_availability'] = table_PATSTAT['publn_nr'].map(mapp).fillna('No')\n",
    "        mapp = {}\n",
    "        mapp['CLAIM'] = 'Yes'\n",
    "        table_PATSTAT['claims_availability'] = table_PATSTAT['claims_availability'].map(mapp).fillna(table_PATSTAT['claims_availability'])\n",
    "        # if we have a claim, we drop duplicates for the other (unmatched) publication numbers\n",
    "        table_PATSTAT.sort_values(by = 'claims_availability', ascending = False, inplace = True)\n",
    "        table_PATSTAT.drop_duplicates(subset = 'appln_id', inplace = True)\n",
    "        return table_PATSTAT\n",
    "    \n",
    "    def set_plotting_style():\n",
    "        import matplotlib.pyplot as plt\n",
    "        # use the 'seaborn-colorblind' style\n",
    "        plt.style.use('seaborn-paper')\n",
    "        sns.set(rc={'figure.figsize':(16,4)})\n",
    "        \n",
    "    def plot_claim_data_availability(table_PATSTAT):\n",
    "\n",
    "        import seaborn as sns\n",
    "        df = table_PATSTAT[table_PATSTAT['appln_auth']=='EP']\n",
    "\n",
    "        # data availability according to patent authority\n",
    "        #g = sns.countplot(x='granted', hue='claims_availability', data=table_PATSTAT)\n",
    "        #g.set_xticklabels(g.get_xticklabels(), rotation=90);\n",
    "        \n",
    "        ## I WAS THERE\n",
    "        nb_claims_available = len(table_PATSTAT[table_PATSTAT['claims_availability']=='Yes'])\n",
    "        proportion_of_claims_available = nb_claims_available/len(table_PATSTAT)*100\n",
    "        \n",
    "        return proportion_of_claims_available\n",
    "        \n",
    "    def display_claims_availability(data):\n",
    "        data = wrap.select_columns(data)\n",
    "        df = wrap.merge_data(data)\n",
    "\n",
    "        table_PATSTAT = wrap.reshape_PATSTAT_data(data)\n",
    "        table_PATSTAT = wrap.add_citations(data, table_PATSTAT)\n",
    "        table_EP_full_text = wrap.reshape_EP_full_text_data(data)\n",
    "        table_PATSTAT = wrap.merge_final_datasets(table_EP_full_text, table_PATSTAT)\n",
    "\n",
    "        wrap.set_plotting_style()\n",
    "        proportion_of_claims_available = wrap.plot_claim_data_availability(table_PATSTAT)\n",
    "        return proportion_of_claims_available\n",
    "    \n",
    "    def get_model_stats(step,mod):\n",
    "        \"\"\"Display summary statistics about the patents remaing in the data at each cleaning step\"\"\"\n",
    "\n",
    "        # numbers of patents in the dataset\n",
    "        a = len(mod.data['_table_main_patent_infos'][Config.VAR_APPLN_ID].unique().tolist())\n",
    "        #print('..Nb of patents:',a)\n",
    "\n",
    "        # number of patent families in the dataset\n",
    "        b = len(mod.data['_table_main_patent_infos'][Config.VAR_DOCDC_FAMILY_ID].unique().tolist())\n",
    "        #print('..Nb of patent families',b)\n",
    "\n",
    "        # average family citation per year count\n",
    "        c = mod.data['_table_main_patent_infos'][Config.NEW_VAR_NB_CITING_DOCDB_FAM_BY_YEAR].mean()\n",
    "        #print('..Average count of family citation per year:',c)\n",
    "\n",
    "        # availability of the patent claim data\n",
    "        df = mod.data.copy()\n",
    "\n",
    "        d = wrap.display_claims_availability(df)\n",
    "        #print('..Claim text availability', d)\n",
    "\n",
    "        return step,a, b, round(c,2) , str(round(d,2))+'%'\n",
    "    \n",
    "    def create_table_data_cleaning(model):\n",
    "\n",
    "        rows = []\n",
    "\n",
    "        rows.append(wrap.get_model_stats(\"Input dataset\", model))\n",
    "\n",
    "        import copy \n",
    "        # step1\n",
    "        model = DataCleaning._keep_only_EP_patents(model)\n",
    "        rows.append(wrap.get_model_stats('EP patents only', copy.deepcopy(model)))\n",
    "        # step 2\n",
    "        model = DataCleaning._select_time_range(model)\n",
    "        rows.append(wrap.get_model_stats('Select time range', copy.deepcopy(model)))\n",
    "        # step 3\n",
    "        model = DataCleaning._keep_only_granted_patents(model)\n",
    "        rows.append(wrap.get_model_stats('Granted patents only', copy.deepcopy(model)))\n",
    "        # step 4\n",
    "        model = DataCleaning._select_one_patent_per_family(model)\n",
    "        rows.append(wrap.get_model_stats('One patent per family', copy.deepcopy(model)))\n",
    "        # step 5\n",
    "        model = DataCleaning._select_breakthrough_patents(model)\n",
    "        rows.append(wrap.get_model_stats('Breakthrough patents', copy.deepcopy(model)))\n",
    "\n",
    "        df = pd.DataFrame(rows, columns=[\"step\",\"nb_patents\", \"nb_patent_fam\", \"av_count_fam_cit_per_year\", \"claim_text_availability\"])\n",
    "\n",
    "        return df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>step</th>\n",
       "      <th>nb_patents</th>\n",
       "      <th>nb_patent_fam</th>\n",
       "      <th>av_count_fam_cit_per_year</th>\n",
       "      <th>claim_text_availability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Input dataset</td>\n",
       "      <td>9160</td>\n",
       "      <td>8679</td>\n",
       "      <td>1.53</td>\n",
       "      <td>80.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EP patents only</td>\n",
       "      <td>9160</td>\n",
       "      <td>8679</td>\n",
       "      <td>1.53</td>\n",
       "      <td>80.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Select time range</td>\n",
       "      <td>8029</td>\n",
       "      <td>7582</td>\n",
       "      <td>1.55</td>\n",
       "      <td>83.12%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Granted patents only</td>\n",
       "      <td>3573</td>\n",
       "      <td>3439</td>\n",
       "      <td>1.69</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>One patent per family</td>\n",
       "      <td>3439</td>\n",
       "      <td>3439</td>\n",
       "      <td>1.33</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Breakthrough patents</td>\n",
       "      <td>694</td>\n",
       "      <td>694</td>\n",
       "      <td>3.13</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(wrap.create_table_data_cleaning(model).to_html(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Add to the table above:**\n",
    "- Nb of clusters identified\n",
    "- Modularity\n",
    "- Content of the clusters\n",
    "\n",
    "=> pb: the unfiltered data is too large... many try against a random selection (for the breakthrough patents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "#model._data_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1\n",
    "#model = DataCleaning._keep_only_EP_patents(model)\n",
    "# step 2\n",
    "#model = DataCleaning._select_time_range(model)\n",
    "# step 3\n",
    "#model = DataCleaning._keep_only_granted_patents(model)\n",
    "# step 4\n",
    "#model = DataCleaning._select_one_patent_per_family(model)\n",
    "# step 5\n",
    "#model = DataCleaning._select_breakthrough_patents(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape in an OOP manner before building the network\n",
    "model._fit_to_object_oriented_design()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving all types of citations\n",
    "model._get_citations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'publication_number'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'publication_number'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7e7c9580f090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Search in the full text database the patents of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_full_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-53a926ad2743>\u001b[0m in \u001b[0;36m_get_full_text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"Retrieve the full text data corresponding to the patents in the model, \n\u001b[1;32m     65\u001b[0m         extract the claims and attribute them to the patent objects\"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetrieveFullTextData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_full_text_to_patents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetrieveFullTextData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attribute_claims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7db7028766d6>\u001b[0m in \u001b[0;36m_assign_full_text_to_patents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \"\"\"\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mlista\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_text_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'publication_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_text_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'publication_number'"
     ]
    }
   ],
   "source": [
    "# Search in the full text database the patents of interest\n",
    "model._get_full_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing, construction of the feature space and computation of all pairwise similarities\n",
    "model._text_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builing the NLP-based patent network\n",
    "model._build_patent_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualisation._draw_graph_with_communities(model);   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualisation._display_cluster_word_clouds(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
